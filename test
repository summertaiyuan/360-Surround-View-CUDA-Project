import rclpy
import tf2_ros
import tf2_geometry_msgs
from geometry_msgs.msg import TransformStamped, PointStamped
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
import cv2
import numpy as np
from rclpy.node import Node
from std_msgs.msg import Header
import message_filters

class CharucoDetector(Node):
    QUEUE_SIZE = 10

    

    def __init__(self):
        super().__init__('charuco_detector')

        # 创建 CvBridge 对象，用于将 ROS 图像消息转换为 OpenCV 图像
        self.bridge = CvBridge()

        # 创建 tf2 监听器和缓冲区
        self.tf_buffer = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer, self)

        self.image_topic = "/camera/color/image_raw"
        self.depth_topic = "/camera/aligned_depth_to_color/image_raw"


        self.image_subscription = message_filters.Subscriber(
            self, Image, self.image_topic
        )
        self.depth_subscription = message_filters.Subscriber(
            self, Image, self.depth_topic
        )

        
        self.time_synchronizer = message_filters.TimeSynchronizer(
            [self.image_subscription, self.depth_subscription], self.QUEUE_SIZE
        )
        
        self.time_synchronizer.registerCallback(self.image_callback)
        self.publisher = self.create_publisher(Image, '/camera/image_with_charuco', 10)

        # 创建 ArUco 字典和 Charuco 标定板
        self.aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_5X5_1000)
        self.board = cv2.aruco.CharucoBoard_create(8, 8, 0.025, 0.018, self.aruco_dict)

                # 3. 相机的内参矩阵 (fx, fy, cx, cy)
        self.K = np.array([[638.8504638671875, 0.0, 631.90869140625],
                    [0.0, 638.1204833984375, 355.4020080566406],
                    [0.0, 0.0, 1.0]])

        # 4. 畸变系数
        self.dist_coeffs = np.array([-0.05560653656721115, 0.05992448702454567, 0.00018415431259199977,
                                0.0008387389243580401, -0.018933113664388657])
            

            # 相机的四元数和平移向量
        self.translation_ee_to_camera = np.array([-0.0037762439456963653, -0.007380776932747355, -0.0023419348644701664, 0.9999628890386993])
        self.rotation_ee_to_camera= np.array([-0.005412330804681288, -0.059305304099402406, -0.09802142228271082])

        
        self.contrast = []
    def transform_points(self, image_points, depth_values):
            """
            将图像点和深度值集转换为 left_base_link 坐标系下的 3D 坐标
            :param image_points: 一个包含所有图像点 (u, v) 坐标的列表
            :param depth_values: 与图像点对应的深度值列表
            :return: 转换后的 3D 坐标列表
            """
            transformed_points = []

            # 获取 `left_ee_link` 到 `left_base_link` 的 TF 转换
            try:
                transform_base_to_ee = self.tf_buffer.lookup_transform('left_base_link', 'left_ee_link', rclpy.time.Time())

                # 遍历每个图像点和深度值
                for i in range(len(image_points)):
                    u, v = image_points[i]
                    Z = depth_values[i]

                    if Z == 0:  # 如果深度值为0，跳过
                        continue

                    # 校正畸变
                    pts_undistorted = cv2.undistortPoints(np.array([[[u, v]]], dtype=np.float32), self.camera_matrix, self.dist_coeffs)

                    # 获取校正后的像素坐标 (u', v')
                    u_undistorted, v_undistorted = pts_undistorted[0][0]

                    # 使用校正后的像素坐标计算 3D 坐标（相机坐标系下的）
                    X = (u_undistorted - self.cx) * Z / self.fx
                    Y = (v_undistorted - self.cy) * Z / self.fy

                    # 将相机坐标系中的点转换为 left_ee_link 坐标系
                    point_in_camera = np.array([X, Y, Z])

                    # 使用位移和四元数将点从相机坐标系转换到 left_ee_link 坐标系
                    # 四元数到旋转矩阵
                    q = self.rotation_ee_to_camera
                    q_matrix = self.quaternion_to_rotation_matrix(q)

                    # 使用旋转矩阵和位移将点从相机坐标系转换到 left_ee_link 坐标系
                    point_in_ee = np.dot(q_matrix, point_in_camera) + self.translation_ee_to_camera

                    # 将 left_ee_link 坐标系的点转换到 left_base_link 坐标系
                    point_in_ee_msg = PointStamped()
                    point_in_ee_msg.header.frame_id = 'left_ee_link'
                    point_in_ee_msg.point.x = point_in_ee[0]
                    point_in_ee_msg.point.y = point_in_ee[1]
                    point_in_ee_msg.point.z = point_in_ee[2]

                    # 使用 TF 将 left_ee_link 坐标系下的点转换到 left_base_link 坐标系
                    transformed_point = self.tf_buffer.transform(point_in_ee_msg, 'left_base_link')

                    # 保存转换后的点
                    transformed_points.append((transformed_point.point.x,
                                            transformed_point.point.y,
                                            transformed_point.point.z))

            except tf2_ros.TransformException as e:
                self.get_logger().error(f"Transform error: {e}")
            except Exception as e:
                self.get_logger().error(f"Error processing points: {e}")

            return transformed_points
        

    def image_callback(self, image_msg, depth_msg):
        try:
            # transform = self.tf_buffer.lookup_transform('left_base_link', 'left_ee_link', rclpy.time.Time())
            depth_image = self.bridge.imgmsg_to_cv2(depth_msg, desired_encoding='32FC1')
            cv_image = self.bridge.imgmsg_to_cv2(image_msg, 'bgr8')
            
            gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
            parameters = cv2.aruco.DetectorParameters_create()
            corners, ids, rejectedImgPoints = cv2.aruco.detectMarkers(gray, self.aruco_dict, parameters=parameters)

            if len(corners) > 0:
                ret, charuco_corners, charuco_ids = cv2.aruco.interpolateCornersCharuco(
                    corners, ids, gray, self.board)
                assert  ret >  0 
                depth_values = [depth_image[int(pts[0][1]), int(pts[0][0])]    for pts  in charuco_corners]
                if ret > 0:
                    cv2.aruco.drawDetectedCornersCharuco(cv_image, charuco_corners[-7:], charuco_ids[-7:])
                    output_msg = self.bridge.cv2_to_imgmsg(cv_image, encoding="bgr8")
                    output_msg.header = Header()
                    output_msg.header.stamp = self.get_clock().now().to_msg()
                    self.publisher.publish(output_msg)
            image_points =  charuco_corners.reshape(charuco_corners.shape[0],-1)
            # transformed_points = self.transform_points(image_points, depth_values)
            # print(transformed_points)

            
            cv2.imshow("Charuco Detection", cv_image)
            key =  cv2.waitKey(1) & 0xFF
            
            if key == ord('q'):
                self.contrast.append(image_points)
            elif key == ord('x'):

                pass
                

        except Exception as e:
            self.get_logger().error('Error processing image: %s' % str(e))

 def quaternion_to_rotation_matrix(self, q):
        """
        将四元数转换为旋转矩阵
        :param q: 四元数 [x, y, z, w]
        :return: 3x3 旋转矩阵
        """
        x, y, z, w = q
        R = np.array([
            [1 - 2*y**2 - 2*z**2, 2*x*y - 2*z*w, 2*x*z + 2*y*w],
            [2*x*y + 2*z*w, 1 - 2*x**2 - 2*z**2, 2*y*z - 2*x*w],
            [2*x*z - 2*y*w, 2*y*z + 2*x*w, 1 - 2*x**2 - 2*y**2]
        ])
        return R

def main(args=None):
    rclpy.init(args=args)
    
    # 创建节点
    charuco_detector = CharucoDetector()

    # 持续运行节点
    rclpy.spin(charuco_detector)

    # 销毁节点并清理
    charuco_detector.destroy_node()
    rclpy.shutdown()
    cv2.destroyAllWindows()

if __name__ == '__main__':
    main()



import rclpy
import numpy as np
import shutil
from rclpy.node import Node
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
import cv2
import os
from datetime import datetime
import matplotlib.pyplot as plt


class ImageSaverNode(Node):
    def __init__(self):
        super().__init__('image_saver_node')
        self.left_subscription = self.create_subscription(
            Image,
            '/depth',
            self.listener_left_callback,
            10)

        self.right_subscription = self.create_subscription(
            Image,
            '/depth',
            self.listener_right_callback,
            10)
        self.bridge = CvBridge()
        self.image_count = 0
        self.save_path = './data/normal/' # 设置保存路径
        self.ensure_directory_exists(self.save_path)

        self.save_image = self.create_timer(1.0/15, self.timer_callback)
        
        self.left_image , self.right_image = None , None
        self.msg = None
        self.pause = False

    def ensure_directory_exists(self, path):

        if not os.path.exists(path):
            os.makedirs(path)
            self.get_logger().info(f'Created directory: {path}')
        else:
            shutil.rmtree(path)
            self.get_logger().info(f'delete  directory: {path}')
    
    def listener_left_callback(self, msg):
        try:
            self.left_image = self.bridge.imgmsg_to_cv2(msg)
            self.msg = msg 
        except Exception as e:
            self.get_logger().error('Failed to convert image message to cv2 image: %s' % e)
            return
        
    def listener_right_callback(self, msg):
        try:
            self.right_image= self.bridge.imgmsg_to_cv2(msg)
            self.msg = msg
        except Exception as e:
            self.get_logger().error('Failed to convert image message to cv2 image: %s' % e)
            return

    def timer_callback(self):

        timestamp = self.msg.header.stamp.sec * 1000000 + self.msg.header.stamp.nanosec // 1000  # 微秒
        timestamp_str = datetime.fromtimestamp(timestamp / 1000000).strftime('%Y%m%d_%H%M%S%f')[:-3]
        left_image_filename = os.path.join(self.save_path, f'{timestamp_str}_left.png')  
        right_image_filename = os.path.join(self.save_path, f'{timestamp_str}_right.png')  

        images = np.hstack((self.left_image. self.right_image))
        plt.imshow(images)
        plt.show()
        
        key =  cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            self.pause = True
        elif key == ord('c'):
            self.pause = False

        if not self.pause:
            cv2.imwrite(left_image_filename, self.left_image)
            cv2.imwrite(right_image_filename, self.right_image)
            self.get_logger().info(f'Saved image: {self.left_image_filename}')

        

def main(args=None):
    rclpy.init(args=args)
    image_saver_node = ImageSaverNode()
    rclpy.spin(image_saver_node)

    # 销毁节点
    image_saver_node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()


